{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Scattertext to Explore the Effectiveness of Headlines\n",
    "### Jason S. Kessler ([@jasonkessler](http://www.twitter.com/JasonKessler))\n",
    "\n",
    "The code in this notebook shows how you can use the Python package Scattertext to explore how language used in headlines \n",
    "can correlate with social engagement.\n",
    "\n",
    "For background on the term-class association scores used and semiotic squares, please see https://github.com/JasonKessler/PuPPyTalk and https://github.com/JasonKessler/SemioticSquaresTalk\n",
    "\n",
    "This notebook makes heavy use of the library Scattertext (https://github.com/JasonKessler/scattertext) for language processing and visualizations.\n",
    "\n",
    "The data used were scraped from Facebook by Max Woolf.  Please see his original notebook at https://github.com/minimaxir/clickbait-cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:98% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import umap\n",
    "import spacy\n",
    "import scattertext as st\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "from glob import glob\n",
    "from scipy.stats import rankdata\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:98% !important; }</style>\"))\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "Let's first parse a dataset of headlines from either BuzzFeed or the NYTimes. These are associated with Facebook reaction counts, and are binned into High, Medium, and Low reaction segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', parser=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>page_id</th>\n",
       "      <th>status_id</th>\n",
       "      <th>link_name</th>\n",
       "      <th>status_published</th>\n",
       "      <th>num_reactions</th>\n",
       "      <th>publication</th>\n",
       "      <th>parse</th>\n",
       "      <th>reaction_percentile</th>\n",
       "      <th>reaction_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>21898300328_10154928658355329</td>\n",
       "      <td>Here's How Much The Kardashians Have Changed I...</td>\n",
       "      <td>2016-08-12 21:31:00</td>\n",
       "      <td>349</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>(Here, 's, How, Much, The, Kardashians, Have, ...</td>\n",
       "      <td>0.024744</td>\n",
       "      <td>Lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>21898300328_10154928707445329</td>\n",
       "      <td>21 Memes That Are Too Pure For This World</td>\n",
       "      <td>2016-08-12 20:46:00</td>\n",
       "      <td>3622</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>(21, Memes, That, Are, Too, Pure, For, This, W...</td>\n",
       "      <td>0.444981</td>\n",
       "      <td>Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>21898300328_10154928683205329</td>\n",
       "      <td>Michael Phelps' Son Looks Like An Old Man And ...</td>\n",
       "      <td>2016-08-12 20:01:01</td>\n",
       "      <td>2667</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>(Michael, Phelps, ', Son, Looks, Like, An, Old...</td>\n",
       "      <td>0.344196</td>\n",
       "      <td>Mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>21898300328_10154925295010329</td>\n",
       "      <td>Here's What The Cast Of \"Degrassi: The Next Ge...</td>\n",
       "      <td>2016-08-12 19:16:01</td>\n",
       "      <td>2461</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>(Here, 's, What, The, Cast, Of, \", Degrassi, :...</td>\n",
       "      <td>0.319553</td>\n",
       "      <td>Lo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>21898300328_10154928549130329</td>\n",
       "      <td>19 Tweets About Michael Phelps That Are Exactl...</td>\n",
       "      <td>2016-08-12 18:31:00</td>\n",
       "      <td>9137</td>\n",
       "      <td>BuzzFeed</td>\n",
       "      <td>(19, Tweets, About, Michael, Phelps, That, Are...</td>\n",
       "      <td>0.770871</td>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   page_id                      status_id  \\\n",
       "0      0  BuzzFeed  21898300328_10154928658355329   \n",
       "1      1  BuzzFeed  21898300328_10154928707445329   \n",
       "2      2  BuzzFeed  21898300328_10154928683205329   \n",
       "3      3  BuzzFeed  21898300328_10154925295010329   \n",
       "4      4  BuzzFeed  21898300328_10154928549130329   \n",
       "\n",
       "                                           link_name    status_published  \\\n",
       "0  Here's How Much The Kardashians Have Changed I... 2016-08-12 21:31:00   \n",
       "1          21 Memes That Are Too Pure For This World 2016-08-12 20:46:00   \n",
       "2  Michael Phelps' Son Looks Like An Old Man And ... 2016-08-12 20:01:01   \n",
       "3  Here's What The Cast Of \"Degrassi: The Next Ge... 2016-08-12 19:16:01   \n",
       "4  19 Tweets About Michael Phelps That Are Exactl... 2016-08-12 18:31:00   \n",
       "\n",
       "   num_reactions publication  \\\n",
       "0            349    BuzzFeed   \n",
       "1           3622    BuzzFeed   \n",
       "2           2667    BuzzFeed   \n",
       "3           2461    BuzzFeed   \n",
       "4           9137    BuzzFeed   \n",
       "\n",
       "                                               parse  reaction_percentile  \\\n",
       "0  (Here, 's, How, Much, The, Kardashians, Have, ...             0.024744   \n",
       "1  (21, Memes, That, Are, Too, Pure, For, This, W...             0.444981   \n",
       "2  (Michael, Phelps, ', Son, Looks, Like, An, Old...             0.344196   \n",
       "3  (Here, 's, What, The, Cast, Of, \", Degrassi, :...             0.319553   \n",
       "4  (19, Tweets, About, Michael, Phelps, That, Are...             0.770871   \n",
       "\n",
       "  reaction_bin  \n",
       "0           Lo  \n",
       "1          Mid  \n",
       "2          Mid  \n",
       "3           Lo  \n",
       "4           Hi  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([\n",
    "    pd.read_csv(fn, sep='\\t')\n",
    "    .assign(publication=fn.split('/')[-1].split('_')[0]) \n",
    "    for fn in glob('./fb_headlines/*')\n",
    "]).reset_index().assign(\n",
    "    status_published = pd.to_datetime(df.status_published)\n",
    ")[\n",
    "    lambda df: df.status_published.apply(lambda x: x.year >= 2016) & df.page_id.isin(['BuzzFeed', 'NYTimes'])\n",
    "].loc[\n",
    "    lambda df: df['link_name'].dropna().index\n",
    "].assign(\n",
    "    parse = lambda df: df.link_name.apply(nlp)\n",
    ").loc[\n",
    "    lambda df: df.parse.apply(len) > 2\n",
    "].assign(\n",
    "    reaction_percentile = lambda df: df.groupby('publication')['num_reactions'].apply(lambda x: pd.Series(rankdata(x)/len(x), index=x.index)),\n",
    "    reaction_bin = lambda df: df.reaction_percentile.apply(lambda x: 'Hi' if x > 2./3 else 'Lo' if x < 1./3 else 'Mid')\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a corpus\n",
    "Next, we'll build a Scattertext corpus from this data. Let's include noun phrase which occurred in the data as features in the corpus. We'll ensure that each feature occurred at least twice in a reaction bin. In bins with more total tokens, the minimum number of occurrences needed is the equivalent to twice in the lowest bin. This is referred to as a `ClassPercentageCompactor`.\n",
    "\n",
    "Since we'll generate a number of redunant noun phrase (e.g., the phrase \"United States of America\" will generate `[United States], [America], [States], [States of America], [United States of America]` as noun phraess) we keep noun phrases that are found in larger noun pharses if they occurred at least five times outside of the surrounding phrase. This is accomplished the the `CompactTerms` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "reaction_corpus = st.CorpusFromParsedDocuments(\n",
    "    df, \n",
    "    parsed_col='parse', \n",
    "    category_col='reaction_bin',\n",
    "    feats_from_spacy_doc=st.PhraseMachinePhrases()\n",
    ").build(\n",
    ").compact(\n",
    "    st.ClassPercentageCompactor(term_count=2)\n",
    ").compact(\n",
    "    st.CompactTerms(slack=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique phrases found: 624\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of unique phrases found:\", len(reaction_corpus.get_terms()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's look at phrase-reaction association\n",
    "It's clear that presidential candidaets are used frequently and associated with more reactions.  Branded content from the NYT underperforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_from_corpus(corpus):\n",
    "    df = corpus.get_df()\n",
    "    return (df.page_id + ', ' \n",
    "            + df.reaction_percentile.apply(lambda x: str(int(x * 100)) + '%') + ', ' \n",
    "            + df.status_published.apply(lambda x: str(x.date())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonkessler/anaconda3/envs/py38/lib/python3.7/site-packages/scattertext-0.0.2.76-py3.7.egg/scattertext/termscoring/ScaledFScore.py:296: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = cat_word_counts * 1. / cat_word_counts.sum()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"reaction_all.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb1346f6690>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(\n",
    "    reaction_corpus,\n",
    "    category='Hi',\n",
    "    not_categories=['Lo'],\n",
    "    neutral_categories=['Mid'],\n",
    "    neutral_category_name='Mid',\n",
    "    minimum_term_frequency=0,\n",
    "    pmi_filter_thresold=0,\n",
    "    use_full_doc = True,\n",
    "    term_scorer = st.DeltaJSDivergence(),\n",
    "    width_in_pixels=1000,\n",
    "    metadata=get_metadata_from_corpus(reaction_corpus),\n",
    "    show_neutral=True,\n",
    "    show_characteristic=False\n",
    ")\n",
    "file_name = 'reaction_all.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at unigram frequencies, we notice similar trends in the high converting content, but the second person pronoun correlates to lower performing content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2907"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reaction_corpus_unigram = (st.CorpusFromParsedDocuments(df, parsed_col='parse', category_col='reaction_bin')\n",
    "                           .build()\n",
    "                           .compact(st.ClassPercentageCompactor(term_count=3))).get_unigram_corpus()\n",
    "reaction_corpus_unigram.get_num_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"reaction_unigram.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb1361291d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_frequency_explorer(reaction_corpus_unigram,\n",
    "                                     category='Hi',\n",
    "                                     not_categories=['Lo'],\n",
    "                                     neutral_categories=['Mid'],\n",
    "                                     neutral_category_name='Mid',\n",
    "                                     minimum_term_frequency=6,\n",
    "                                     pmi_filter_thresold=0,\n",
    "                                     use_full_doc = True,\n",
    "                                     term_scorer = st.DeltaJSDivergence(),\n",
    "                                     grey_threshold=0,\n",
    "                                     width_in_pixels=1000,\n",
    "                                     metadata=get_metadata_from_corpus(reaction_corpus),\n",
    "                                     show_neutral=True,\n",
    "                                     show_characteristic=False)\n",
    "file_name = 'reaction_unigram.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use UMAP to cluster unigrams based on their cooccurence statistics, and visually identify semantically sikmilar terms which indicate high or low performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1200\"\n",
       "            height=\"700\"\n",
       "            src=\"reaction_umap_projection.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb1136c2090>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = st.produce_projection_explorer(\n",
    "    reaction_corpus_unigram,\n",
    "    category='Hi', \n",
    "    not_categories=['Lo'], \n",
    "    neutral_categories=['Mid'],\n",
    "    term_scorer = st.RankDifference(),\n",
    "    neutral_category_name='Mid',\n",
    "    width_in_pixels=1000,\n",
    "    use_full_doc=True,\n",
    "    projection_model = umap.UMAP(metric='cosine'),\n",
    "    term_acceptance_re=re.compile(''),\n",
    "    metadata=get_metadata_from_corpus(reaction_corpus_unigram)\n",
    ")\n",
    "file_name = 'reaction_umap_projection.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1200, height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at publication-specific performance, and compare their performances to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = df.publication + ' ' + df.reaction_bin\n",
    "df_four_square = df[df.reaction_bin.isin(['Hi', 'Lo'])]\n",
    "# Create corpus and filter terms\n",
    "four_square_corpus = (st.CorpusFromParsedDocuments(df_four_square, category_col = 'category', parsed_col = 'parse')\n",
    "                      .build()\n",
    "                      .compact(st.CompactTerms(minimum_term_count=2, slack=6))\n",
    "                      .compact(st.ClassPercentageCompactor(term_count=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_square_axes = st.FourSquareAxes(four_square_corpus, \n",
    "                                     ['NYTimes Hi'], \n",
    "                                     ['NYTimes Lo'], \n",
    "                                     ['BuzzFeed Hi'], \n",
    "                                     ['BuzzFeed Lo'], \n",
    "                                     labels = {'a': 'Appeals to all',\n",
    "                                               'a_and_not_b': 'NY Times: Hi Engagement',\n",
    "                                               'b_and_not_a': 'NY Times: Lo Engagement',\n",
    "                                               'a_and_b': 'BuzzFeed: Hi Engagement',\n",
    "                                               'not_a_and_not_b': 'BuzzFeed: Lo Engagement',\n",
    "                                               'not_a': 'Ignored by all',\n",
    "                                               'b': 'Ignored by elite, appeals to masses',\n",
    "                                               'not_b': 'Appeals to elite, ignored by masses'})\n",
    "html = st.produce_four_square_axes_explorer(\n",
    "    four_square_axes=four_square_axes,\n",
    "    x_label='NYT: Hi-Lo',\n",
    "    y_label='Buzz: Hi-Lo',\n",
    "    use_full_doc=True,\n",
    "    pmi_threshold_coefficient=0,\n",
    "    metadata=get_metadata_from_corpus(four_square_corpus),\n",
    "    censor_points=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1600\"\n",
       "            height=\"900\"\n",
       "            src=\"reaction_axes.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb12bf04ad0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'reaction_axes.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1600, height=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1600\"\n",
       "            height=\"900\"\n",
       "            src=\"reaction_semiotic_censor.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x160e1e6d8>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View chart with multiple terms visible\n",
    "# Set up chart structure\n",
    "four_square = st.FourSquare(\n",
    "    four_square_corpus,\n",
    "    category_a_list=['NYTimes Hi'],\n",
    "    category_b_list=['BuzzFeed Hi'],\n",
    "    not_category_a_list=['BuzzFeed Lo'],\n",
    "    not_category_b_list=['NYTimes Lo'],\n",
    "    scorer=st.RankDifference(),\n",
    "    labels={'a': 'Highbrow Engagment',\n",
    "            'b': 'Lowbrow Engagment',\n",
    "            'not_a_and_not_b': 'Few Facebook Reactions',\n",
    "            'a_and_b': 'Many Facebook Reactions',\n",
    "            'a_and_not_b': 'NYTimes',\n",
    "            'b_and_not_a': 'BuzzFeed',\n",
    "            'not_a': 'Lowbrow Ignored',\n",
    "            'not_b': 'Highbrow Ignored'})\n",
    "html = st.produce_four_square_explorer(four_square=four_square,\n",
    "                                       x_label='NYTimes-Buzz',\n",
    "                                       y_label='Hi-Low',\n",
    "                                       use_full_doc=True,\n",
    "                                       pmi_threshold_coefficient=0,\n",
    "                                       metadata=get_metadata_from_corpus(four_square_corpus), \n",
    "                                       censor_points=False)\n",
    "file_name = 'reaction_semiotic_censor.html'\n",
    "open(file_name, 'wb').write(html.encode('utf-8'))\n",
    "IFrame(src=file_name, width = 1600, height=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
