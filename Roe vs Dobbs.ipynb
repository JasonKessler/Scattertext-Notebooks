{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import scattertext as st\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x7ff4d43f3820>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank('en')\n",
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "roe_opinion = BeautifulSoup(\n",
    "    requests.get('https://www.law.cornell.edu/supremecourt/text/410/113').content, \n",
    "    \"html.parser\"\n",
    ").find('div', attrs={'class': 'bodytext'}).text\n",
    "\n",
    "# Note: this is from an OCR performed via OSX preview\n",
    "dobbs_draft_opinion = open('draft_opinion.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_df = pd.DataFrame([\n",
    "    {'Title': 'Roe','Text': roe_opinion},\n",
    "    {'Title': 'Dobbs','Text': dobbs_draft_opinion},\n",
    "]).assign(\n",
    "    Parse = lambda df: df.Text.apply(nlp)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = st.CorpusFromParsedDocuments(\n",
    "    case_df,\n",
    "    category_col = 'Title',\n",
    "    parsed_col = 'Parse'\n",
    ").build().remove_infrequent_words(\n",
    "    4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1697337"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "html = st.produce_scattertext_explorer(\n",
    "    corpus,\n",
    "    category='Roe', \n",
    "    not_category_name='Dobbs',\n",
    "    minimum_term_frequency=0, \n",
    "    pmi_threshold_coefficient=0,\n",
    "    width_in_pixels=1000, \n",
    "    transform=st.Scalers.dense_rank\n",
    ")\n",
    "\n",
    "open('./roe_vs_dobbs.html', 'w').write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open roe_vs_dobbs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3510"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.get_num_terms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
